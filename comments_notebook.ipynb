{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "# 0. Dependances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false
   },
   "outputs": [],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false
   },
   "outputs": [],
   "source": [
    "print(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/kaggle/input/jigsaw-toxic-comment-classification-challenge/train.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "# 1. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import TextVectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false
   },
   "outputs": [],
   "source": [
    "X = df['comment_text']\n",
    "y = df[df.columns[2:]].values  \n",
    "#.values is to convert the pandas series/dataframe into a numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false
   },
   "outputs": [],
   "source": [
    "MAX_FEATURES = 200000 #number of tokens (words) in a sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false
   },
   "outputs": [],
   "source": [
    "vectorizer = TextVectorization(max_tokens=MAX_FEATURES,\n",
    "                              output_sequence_length=1800,\n",
    "                              output_mode='int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false
   },
   "outputs": [],
   "source": [
    "vectorizer.adapt(X.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false
   },
   "outputs": [],
   "source": [
    "vectorizer(\"Hello, my name is Abdo. Nice to meet you\")[:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false
   },
   "outputs": [],
   "source": [
    "vectorized_text = vectorizer(X.values)\n",
    "vectorized_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "### Basic data pipeline:\n",
    "### MCSHBAP : MAP, CACHE, SHUFFLE, BATCH, PREFETCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false
   },
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((vectorized_text,y))  \n",
    "#TF dataset piepline\n",
    "dataset=dataset.cache().shuffle(160000).batch(16).prefetch(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false
   },
   "outputs": [],
   "source": [
    "dataset.as_numpy_iterator().next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false
   },
   "outputs": [],
   "source": [
    "train = dataset.take(int(0.7*len(dataset)))\n",
    "val = dataset.skip(int(0.7*len(dataset))).take(int(0.2*len(dataset)))\n",
    "test = dataset.skip(int(0.9*len(dataset))).take(int(0.1*len(dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false
   },
   "outputs": [],
   "source": [
    "len(train),len(val),len(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "# 2. Create Sequential Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import LSTM, Dropout, Bidirectional,Dense,Embedding\n",
    "from tensorflow.compat.v1.keras.layers import CuDNNLSTM\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "#Embedding layer: like a character test اختبار شخصية, outputs a vector of word specs\n",
    "model.add(Embedding(MAX_FEATURES+1,32))\n",
    "\n",
    "#Bidirectional LSTM: enables moving to left and right, \n",
    "model.add(Bidirectional(CuDNNLSTM(32))) #GPU with LSTM requires TANH\n",
    "\n",
    "#Feature extractor fully connected layers\n",
    "model.add(Dense(128,activation = 'relu'))\n",
    "model.add(Dense(256,activation = 'relu'))\n",
    "model.add(Dense(128,activation = 'relu'))\n",
    "\n",
    "#Output layer\n",
    "model.add(Dense(6,activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Bidirectional, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.compat.v1.keras.layers import CuDNNGRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# Define the model architecture\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=MAX_FEATURES+1, output_dim=32, input_length=max_sequence_length))\n",
    "model.add(Dropout(0.2))  # Add dropout for regularization\n",
    "model.add(Bidirectional(CuDNNGRU(64)))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(6, activation='softmax'))\n",
    "\n",
    "# Add batch normalization layers\n",
    "model.add(BatchNormalization())\n",
    "model.add(BatchNormalization())\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Print the model summary\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false
   },
   "outputs": [],
   "source": [
    "model.compile(loss = 'BinaryCrossentropy',optimizer='Adam',metrics='accuracy')\n",
    "#BinaryCrossentropy because this is not a classification problem where output \n",
    "#must be a 1 and the rest are zeros, in this problem, a comment can be \n",
    "#severe toxix and threat at the same time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false
   },
   "outputs": [],
   "source": [
    "history = model.fit(train,epochs=1,validation_data=val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false
   },
   "outputs": [],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false
   },
   "outputs": [],
   "source": [
    "model.evaluate(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "# 3. Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false
   },
   "outputs": [],
   "source": [
    "input_text = vectorizer(\"You suck!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false
   },
   "outputs": [],
   "source": [
    "df.columns[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false
   },
   "outputs": [],
   "source": [
    "predictions = model.predict(np.expand_dims(input_text,0))\n",
    "results = {}\n",
    "for i in range(6):\n",
    "    results[df.columns[2:][i]] = predictions[0][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false
   },
   "outputs": [],
   "source": [
    "for k in results.keys():\n",
    "    if results[k]<0.5:\n",
    "        results[k]=0\n",
    "    else:\n",
    "        results[k]=1\n",
    "        \n",
    "results\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "# 4. Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.metrics import Precision,Recall,CategoricalAccuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false
   },
   "outputs": [],
   "source": [
    "pre = Precision()\n",
    "re = Recall()\n",
    "acc = CategoricalAccuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for batch in test.as_numpy_iterator():\n",
    "    X_true,y_true = batch\n",
    "    yhat = model.predict(X_true)\n",
    "    \n",
    "    y_true = y_true.flatten()\n",
    "    yhat = yhat.flatten()\n",
    "    \n",
    "    pre.update_state(y_true,yhat)\n",
    "    re.update_state(y_true,yhat)\n",
    "    acc.update_state(y_true,yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false
   },
   "outputs": [],
   "source": [
    "print(f\"Precession: {pre.result().numpy()},Recall: {re.result().numpy()},Accuracy: {acc.result().numpy()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model as tfk__load_model\n",
    "# save fitted model to file\n",
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
